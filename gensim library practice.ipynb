{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize # load tokenize module\n",
    "from collections import Counter #load count module\n",
    "from nltk.corpus import stopwords #utilize stopwords\n",
    "from pprint import pprint as pp #pretty print\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text= \"\"\"\n",
    "\"This new version of global economy can help the Italian economy to recover and speed up growth, reducing unemployment through new investments. It can also affect inward and outward FDI (foreign direct investment),\" he added.\n",
    "\n",
    "Duncan Freeman, a research fellow at the EU-China Research Center, agreed it was a visit full of symbolism.\"President Xi Jinping's choice of the European Union as the first stop not only reflects the importance of the EU for China in the long term, but also shows the importance of the moment globally since we together face a very difficult situation in terms of global economy and international relations,\" he said.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(raw_text.lower()) #transform the raw doc to tokenized words , but the tokens includes some unuseful words \n",
    "tokens_stops = [w for w in tokens if w.isalpha() if w not in stopwords.words('english')]\n",
    "count_tokens = Counter(tokens_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('economy', 3),\n",
      " ('new', 2),\n",
      " ('global', 2),\n",
      " ('also', 2),\n",
      " ('research', 2),\n",
      " ('importance', 2),\n",
      " ('version', 1),\n",
      " ('help', 1),\n",
      " ('italian', 1),\n",
      " ('recover', 1)]\n"
     ]
    }
   ],
   "source": [
    "pp(count_tokens.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'added': 0, 'affect': 1, 'agreed': 2, 'also': 3, 'center': 4, 'china': 5, 'choice': 6, 'difficult': 7, 'direct': 8, 'duncan': 9, 'economy': 10, 'eu': 11, 'european': 12, 'face': 13, 'fdi': 14, 'fellow': 15, 'first': 16, 'foreign': 17, 'freeman': 18, 'full': 19, 'global': 20, 'globally': 21, 'growth': 22, 'help': 23, 'importance': 24, 'international': 25, 'investment': 26, 'investments': 27, 'inward': 28, 'italian': 29, 'jinping': 30, 'long': 31, 'moment': 32, 'new': 33, 'outward': 34, 'president': 35, 'recover': 36, 'reducing': 37, 'reflects': 38, 'relations': 39, 'research': 40, 'said': 41, 'shows': 42, 'since': 43, 'situation': 44, 'speed': 45, 'stop': 46, 'symbolism': 47, 'term': 48, 'terms': 49, 'together': 50, 'unemployment': 51, 'union': 52, 'version': 53, 'visit': 54, 'xi': 55}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use gensim library to create Dictionary\n",
    "from  gensim.corpora.dictionary import Dictionary\n",
    "type(tokens_stops)\n",
    "dictionary = Dictionary([tokens_stops])\n",
    "dictionary.token2id #build the unique mapping between word and id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1),\n",
      "  (1, 1),\n",
      "  (2, 1),\n",
      "  (3, 2),\n",
      "  (4, 1),\n",
      "  (5, 1),\n",
      "  (6, 1),\n",
      "  (7, 1),\n",
      "  (8, 1),\n",
      "  (9, 1),\n",
      "  (10, 3),\n",
      "  (11, 1),\n",
      "  (12, 1),\n",
      "  (13, 1),\n",
      "  (14, 1),\n",
      "  (15, 1),\n",
      "  (16, 1),\n",
      "  (17, 1),\n",
      "  (18, 1),\n",
      "  (19, 1),\n",
      "  (20, 2),\n",
      "  (21, 1),\n",
      "  (22, 1),\n",
      "  (23, 1),\n",
      "  (24, 2),\n",
      "  (25, 1),\n",
      "  (26, 1),\n",
      "  (27, 1),\n",
      "  (28, 1),\n",
      "  (29, 1),\n",
      "  (30, 1),\n",
      "  (31, 1),\n",
      "  (32, 1),\n",
      "  (33, 2),\n",
      "  (34, 1),\n",
      "  (35, 1),\n",
      "  (36, 1),\n",
      "  (37, 1),\n",
      "  (38, 1),\n",
      "  (39, 1),\n",
      "  (40, 2),\n",
      "  (41, 1),\n",
      "  (42, 1),\n",
      "  (43, 1),\n",
      "  (44, 1),\n",
      "  (45, 1),\n",
      "  (46, 1),\n",
      "  (47, 1),\n",
      "  (48, 1),\n",
      "  (49, 1),\n",
      "  (50, 1),\n",
      "  (51, 1),\n",
      "  (52, 1),\n",
      "  (53, 1),\n",
      "  (54, 1),\n",
      "  (55, 1)]]\n"
     ]
    }
   ],
   "source": [
    "type(tokens_stops)\n",
    "corpus = [dictionary.doc2bow(tokens_stops)]\n",
    "pp(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
